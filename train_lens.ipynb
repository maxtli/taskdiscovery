{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":110716,"status":"ok","timestamp":1709248989976,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"},"user_tz":480},"id":"-aMBOeruJ2hM","outputId":"bd5aa754-9357-4e56-ccc9-b03f2f851817"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import sys\n","if 'google.colab' in sys.modules:\n","    from google.colab import drive\n","    import os\n","    import subprocess\n","\n","    drive.mount('/content/drive')\n","    os.chdir('/content/drive/Shareddrives/Confidence Probes/taskdiscovery')\n","    subprocess.run(['pip3', 'install', '-r', 'requirements.txt'])\n","\n","else:\n","    print(\"Not running in Google Colab, skipping installation of requirements.\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vcu8hkBJJnb0","colab":{"base_uri":"https://localhost:8080/","height":530},"executionInfo":{"status":"error","timestamp":1709249005179,"user_tz":480,"elapsed":8951,"user":{"displayName":"Alireza Havaeishamsabadi","userId":"17001251423603039459"}},"outputId":"bd98ca97-514b-4e75-c63b-d88b28dae721"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'datasets'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-67646b189bca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtraining_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinePlot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlens\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_lens_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Shareddrives/Confidence Probes/taskdiscovery/training_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mretrieve_owt_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer_lens\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHookedTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/Shareddrives/Confidence Probes/taskdiscovery/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformer_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenize_and_concatenate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from training_utils import load_model_data\n","from training_utils import LinePlot\n","from lens import get_lens_loss\n","import torch\n","from tqdm import tqdm\n","import numpy as np\n","import pickle\n","import math\n"]},{"cell_type":"markdown","metadata":{"id":"1c0Cs24oJnb0"},"source":["## Load model and data\n","We will be using gpt2 small for now."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["810849eea4f84418922ca77032fb3eae","a0e503a870e0483b98ce8ab5e477274a","029a70347ab14efe8be17ff8eb611e3b","49aec8f476dd476fba4b481211ce02b9","abd9b735fa01449fa4d0ff2e2f89fe3d","71999a8410c54f9f982491351ed8bd8c","754fd911f3bc4ab987f28697662480eb","ae5cb034983e475cad1e70c9a60bf213","262bfb8fe4ce4cdaafd50b1cdc7e9592","5501a89010ac4c88853b235a2dae68ae","e37f2d4dca6e45b6b758a75e24cb597d"]},"id":"5gosREQU1_fm","outputId":"e7ebd1f1-be08-455c-f9a0-9be97a2739f6"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"810849eea4f84418922ca77032fb3eae","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0e503a870e0483b98ce8ab5e477274a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"029a70347ab14efe8be17ff8eb611e3b","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49aec8f476dd476fba4b481211ce02b9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abd9b735fa01449fa4d0ff2e2f89fe3d","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71999a8410c54f9f982491351ed8bd8c","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"754fd911f3bc4ab987f28697662480eb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Loaded pretrained model gpt2-small into HookedTransformer\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae5cb034983e475cad1e70c9a60bf213","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/366 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"262bfb8fe4ce4cdaafd50b1cdc7e9592","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/303M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5501a89010ac4c88853b235a2dae68ae","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e37f2d4dca6e45b6b758a75e24cb597d","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/100000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (61422 > 1024). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (58948 > 1024). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (59558 > 1024). Running this sequence through the model will result in indexing errors\n","Token indices sequence length is longer than the specified maximum sequence length for this model (71857 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"name":"stdout","output_type":"stream","text":["12 12 64 768\n"]}],"source":["model_name = \"gpt2-small\"\n","batch_size = 32\n","device, model, tokenizer, owt_iter = load_model_data(model_name, batch_size)\n","n_layers = model.cfg.n_layers\n","n_heads = model.cfg.n_heads\n","head_dim = model.cfg.d_head\n","d_model = model.cfg.d_model\n","lr = 1e-2\n","\n","folder = \"./results/\"\n","shared_bias = False\n","\n","print(n_layers, n_heads, head_dim, d_model)"]},{"cell_type":"markdown","metadata":{"id":"a-zA8hD9Jnb1"},"source":["## Create Modal Lens Prameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2j_RVFxJnb1"},"outputs":[],"source":["prior_bias = [model.blocks[i].attn.b_O.clone() for i in range(n_layers)]\n","\n","attn_bias = [\n","    torch.nn.Parameter(\n","        (prior_bias[i] if shared_bias else prior_bias[i].repeat(i + 1, 1)).to(device)\n","    )\n","    for i in range(n_layers)\n","]\n","\n","lens_optimizer = torch.optim.AdamW(attn_bias, lr=lr, weight_decay=0)\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n"]},{"cell_type":"markdown","metadata":{"id":"t55IAZ3gJnb1"},"source":["## Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlg5uCIwJnb1","outputId":"e196b676-5007-4e02-f6c6-96f9f76cc30a"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5000 [00:00<?, ?it/s]\n"]},{"ename":"TypeError","evalue":"get_lens_loss() missing 4 required positional arguments: 'model', 'n_layers', 'attn_bias', and 'batch_size'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(owt_iter)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m lens_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 7\u001b[0m kl_losses, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_lens_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m kl_losses \u001b[38;5;241m=\u001b[39m kl_losses\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(kl_losses\u001b[38;5;241m.\u001b[39msum(), \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: get_lens_loss() missing 4 required positional arguments: 'model', 'n_layers', 'attn_bias', and 'batch_size'"]}],"source":["lp = LinePlot([*[f\"kl_loss_{k}\" for k in range(n_layers)], \"step_size\"])\n","\n","for i in tqdm(range(5000)):\n","    batch = next(owt_iter)[\"tokens\"]\n","    lens_optimizer.zero_grad()\n","\n","    kl_losses, _ = get_lens_loss(batch, model, n_layers, attn_bias,batch_size)\n","    kl_losses = kl_losses.mean(dim=-1)\n","    loss = torch.clamp(kl_losses.sum(), max=100)\n","    loss.backward()\n","\n","    prev_weights = torch.cat(attn_bias, dim=0).detach()\n","\n","    lens_optimizer.step()\n","\n","    step_sz = (torch.cat(attn_bias, dim=0) - prev_weights).abs().sum()\n","    lp.add_entry(\n","        {\n","            \"step_size\": step_sz.item(),\n","            **{f\"kl_loss_{k}\": kl_losses[k].item() for k in range(n_layers)},\n","        }\n","    )\n","\n","    # lens_scheduler.step()\n","\n","    if math.isnan(lp.stat_book[\"step_size\"][-1]):\n","        break\n","\n","    if i % 250 == 0:\n","        lp.plot(subplots=3, save=f\"{folder}/train.png\", twinx=False, mv=20)\n","        with open(f\"{folder}/modal_lens_weights.pkl\", \"wb\") as f:\n","            pickle.dump(attn_bias, f)"]},{"cell_type":"markdown","metadata":{"id":"atninGWAJnb2"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"td","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":0}